![leafSun](https://user-images.githubusercontent.com/32124230/107999911-9f3f1100-6fe0-11eb-9755-f48dbb82cf65.png)

# DOCUMENTATION

# Table of Contents
* [Background](#background)
  * [Climate data](#climate-data)
  * [Crop data](#crop-data)
* [Basic operation](#basic-operation)
* [Model Tab](#model-tab)
  * [Modelling task](#modelling-task)
  * [Required data format and upload](#required-data-format-and-upload)
  * [Sampling strategy](#sampling-strategy)
  * [Reproducible results](#reproducible-results)
  * [Parallel computing](#parallel-computing)
  * [Results table](#results-table)
  * [Final model version](#final-model-version)
  * [Saving model results](#saving-model-results)
* [Projections tab](#projections-tab)
  * [Climate and crop panel](#climate-and-crop-panel)
  * [Results panel](#results-panel)
  * [Saving projection results](#saving-projection-results)
  
# Background
The app provides a very simple front-end to cutting edge machine learning algorithms, and is bundled with gridded crop distribution and climate change data. With a few button clicks you can fit a weather-dependent regression- or classification-tree ensemble to your own data, apply your model across real crop locations, and explore possible future changes under various climate change scenarios. 

### Climate data
The app uses seasonal 12 km gridded (65 x 112 cells) climate data from the UK Met Office Climate Projections database [UKCP18](https://www.metoffice.gov.uk/research/approach/collaboration/ukcp/index) 12-member ensemble of Regional projections. The following variables are provided: temperature (deg. C), relative humidity (%), wind speed (m s<sup>-1</sup>), net surface shortwave radiation flux (W m<sup>-2</sup>), precipitation (mm d<sup>-1</sup>), total cloud (%). The data are at presented at seasonal timescales (spring, summer, autumn, and winter) for each decade spanning 2020s-2060s. UKCP18 modelled data for 1981-2000 are included as baseline values for comparison. All the climate data have full spatial and temporal coherence, enabling the assessment of multiple climatic drivers of changing hazards across multiple geographic locations. The data provide 12 equally plausible snapshots of climate change for emissions scenario RCP8.5, meaning that fitted models will produce an ensemble of 12 projected values for each grid cell, and a super-ensemble of results for each crop species distribution.

### Crop data
Polygon data defining the spatial coverage of crops and land-use types were derived from [IACS](https://ec.europa.eu/agriculture/direct-support/iacs_en) and [JACS](https://www.gov.scot/collections/june-scottish-agricultural-census/). These data cover Scotland only. The vector data were rasterised to 12 km grids matching the resolution of the climate change data. Information on the abundance (area) of crop in each grid cell is used for visualisation purposes only, and the presence-absence of selected crop species is used to narrow the climate change risk assessment to relevant grid cells.  

# Basic operation
*Tabs*: The app has two 'tabs' - 'Model' and 'Projections.' Click on the tab name to switch from one to the other.  
*Switches*: Drag the circluar switch to the left or right, or click in the empty space.  
*Lists*: Click on the desired option in the list.  
*Buttons*: Click them.  
*Numeric fields*: Click in the white box to change the numerical value, then hit enter or click outside the box.  
*State buttons*: Click them to toggle between two states - dark grey indicates 'on' and light grey is 'off'.  
*Knobs*: Drag the circular control around to your selection, or click on your selection.  
Note: some controls may be unavailable (greyed out) until certain operations have been performed, for example, model results cannot be saved until a model has been fitted to your data.  

# Model Tab
The risk models you create here must be a function of one or more of the weather variables included in the climate change projection data. Inclusion of other weather variables will produce meaningless results. Your 'response variable' (dependent variable) can be any weather-dependent process involving / affecting / occurring in or around crops, e.g., crop diseases, pests, crop growth etc.    

### Modelling task
The app uses the MATLAB commands ``fitrensemble`` to fit regression tree ensembles, and ``fitcensemble`` to fit classification tree ensembles, depending on the required modelling task. This is selected using the 'Task' switch. For regression tasks your Y variable should be continuous and for classification tasks it must be categorical. If an attempt is made to upload data that do not match the selected task, a warning will be issued and the data will not be loaded. 

### Required data format and upload
To upload your data click the 'Load' button. This will open up a dialogue box that allows you to search for your file. Data files must be .xls or .xlsx. Data should be arranged in rows with columns for the different weather variables. The column header for the response (dependent) variable should be an upper case Y, and the column headers for your weather variables should be all lower case: temp, rh, rain, wind, rad, cloud. It doesn't matter what order the columns are in, and you can include as many of the set of 6 weather variables as required. Missing data should be left as blank cells and these will be ignored during model fitting; do not use numerical missing data identifiers (e.g., -9999) as these will be treated as numbers. Text entries will be treated as missing data. Data for classification tasks require a little more consideration. Your categorical response variable must be coded as integers and not any form of character or string array (text, alphanumeric, symbols etc.), e.g., low, medium, and high should be converted to 1, 2, 3. Integers will be treated as discrete classes by the algorithms. This is required to eliminate the risk of typos, use of different date formats etc. You ideally want >25 values of Y for each discrete class. An acceptable performance may be achieved with fewer samples per class, but <5 per class on average will result in a warning and the data will not load. Consider aggregating the classes into fewer categories if the data per class is sparse, and fitting an algorithm on the new data to see if performance is improved. Unbalanced data, where the class proportions are skewed, is not a serious concern as the algorithms are ensembles of decision trees that handle imbalanced data quite well, If the performance of a fitted classifier is poor, however, you may want to consider addressing this via, e.g., upsampling or downsampling. Two synthetic datasets are included for regression and classification, and you can refer to these if in doubt about the required data format. 

### Sampling strategy
The primary objective in applied machine learning is to maximize predictive accuracy on new (unseen) data. Resampling methods are statistical procedures for sampling a dataset that are used to estimate this unknown quantity. The algorithms used in the app have parameters that are learned from the data (known as training) and hyperparameters that affect the learning process, whose value must be set before learning begins (finding the optimal values is known as tuning). Resampling methods use different protions of a dataset for training, tuning, and testing of predictive accuracy. This provides an estimate of how well the entire model building process will perform on average when confronted with new data, and how much it is expected to vary in practice. This is useful for reporting purposes and to compare different algorithms and algorithm versions. Once the skill of a machine learning procedure on unseen data has been estimated we are finished with resampling, we discard all of the trained/tuned models, and move directly to creating the [final model version](#final-model-version). Finalization is done automatically in the app after resampling.  

A number of sampling strategies are provided in the 'Sampling' list. If 'none' is selected then all the data will be used for learning, default values for the hyperparameters will be used (no tuning), and the model will be 'tested' using all the data it has already learned from. This is the least desirable option as it can lead to 'overfitting' and does not provide an estimate of the skill of the process on unseen data. It is, however, the fastest option for obtaining a model to be used in the [Projections tab](#projections-tab) of the app. The next 3 options are prefixed by 'NCV' which stands for nested cross-validation. Cross-validation, or *k*-fold cross-validation, is a useful resampling procedure when the size of the dataset is limited. Cross-validation has a single hyperparameter *k* that controls the number of subsets that a dataset is split into. Once split, each subset is given the opportunity to be used as a test set while all other subsets are combined as the training dataset. This means that *k*-fold cross-validation involves fitting and evaluating *k* versions of an algorithm. This, in turn, provides *k* estimates of an algorithm's performance on the dataset. In nested CV there are two loops of CV: an inner and an outer loop. Each training set of the outer cross-validation is further subdivided into folds in an inner loop of CV to find the best hyperparameter values for that training set. This is achieved using 'Bayesian optimization', via MATLAB's ``bayesopt`` command with *k* = 5. Once the optimal hyperparameter values are found, the algorithm is retrained and tested in the outer loop. This is considered to be the 'gold-standard' approach in machine learning, but it is computationally expensive and may be slow to run depending on the size of your dataset. The outer loop can be *k* = 5, *k* = 10, or 'loocv', which stands for leave-one-out cross-validation. This is an extreme version of *k*-fold cross-validation where *k* is set to the number of examples in the dataset. It requires one model to be created and evaluated for each example in your dataset, and therefore has the maximum computational cost and is not appropriate for large datasets. Finally, there is the 'holdout' option, in which 80% of your data is used for training and tuning in a 5-fold Bayesian optimization, and 20% is 'held out' for testing the optimized algorithm.  

One of the above strategies will be automatically selected for you based on the size of your dataset, but this can be overridden. Automatic selection follows a commonly used approach based on the number of examples  *n* in your dataset: *n* <= 20 = 'loocv', 20 < *n* <= 100 = 10-fold, 100 < *n* <= 10,000 = 5-fold, and *n* > 10,000 = 'holdout'. A value of *k* = 10 is very common in the field of applied machine learning and is recommend if you are struggling to choose a strategy for your dataset. Note that for classification tasks the app implements 'stratified sampling' to ensure that the ratio of the observations in each class remains the same in each sample, which is useful for imbalanced datasets. Also note that prior to sampling the rows of data are randomly shuffled to ensure that samples are representative of the overall distribution of the data, which may not be the case if they have been artificially ordered (by class, for example). 

### Reproducible results
The 'Seed' numeric field specifies the seed for the MATLAB random number generator and can be used to ensure that all random shuffles and splits of the data are fully reproducible, providing reproducible results for the Model tab for the same seed value. Reproducibility can be affected, however, if you set the app to utilise parallel computing (see below).

### Parallel computing
Training, tuning, and testing an algorithm can be computationally expensive, therefore making use of parallel computing is advised if you have a multicore device. This is achieved by depressing the 'Parallel' state button (it will change from light grey to dark grey). This may mean, however, that parallel Bayesian optimization (tuning) does not yield exactly reproducible results, due to the nonreproducibility of parallel timing.

### Train / tune / test results table
Click the 'Run' button to begin model fitting. A progress bar will appear above the table to indicate that computations are underway. The table displays the results for each iteration of the selected sampling strategy. For 'none' and 'holdout' there will be one row and for sampling strategies prefixed by NCV there will be *k* rows of results in the table. These will appear one-by-one as the app cycles through each iteration of sampling. The columns are explained as follows. 'Fold' provides the number of the test fold (i.e., the iteration count). 'Method' provides the best estimated learner (ensemble aggregation algorithm) on the test fold. The next 5 or 6 columns provide the optimized hyperparameter values for regression and classification, respectively (note that column headings for hyperparameters change according to the modelling task selected). The final two columns provide a measure of predictive accuracy on the training fold and test fold. For regression this is the mean squared error of prediction and for classification it is the misclassification rate (proportion of cases misclassified). If 'none' is selected as the sampling strategy then the test accuracy will be NaN (not a number) as no test data were set aside. Although test accuracy is the primary metric of interest, predictive accuracy on training folds is provided for comparison. Performance is often slightly lower on test folds, but if there is a large discrepancy in training and test accuracy it indicates a poor ability of the algorithm to generalize to new, unseen data. For reporting purposes you can provide the individual results on each test fold (Test column) or the mean and SD across the test folds. If NaN appears for any hyperparameter value, this indicates that the best estimated learner does not use that hyperparameter. A description of the various ensemble aggregation algorithms (and their hyperparamters) that can be returned by ``fitrensemble`` and ``fitcensemble``is beyond the scope of this documentation, but the interested reader can consult the [MATLAB documentation](https://www.mathworks.com/help/index.html?s_tid=CRUX_topnav). 

### Final model version
The details of the finalized algorithm will automatically appear in the 'Final version' table after assessment of the model building process via resmapling is complete. If the sampling strategy selected was 'none', then default settings were used for ``fitrensemble`` / ``fitcensemble`` and the default learner has already been trained on all the available data. Otherwise, one more round of Bayesian optimization with 5-fold cross-validation is performed using to obtain the best learner and optimal hyperparameter settings, and the resultant optimized learner is retrained using all the data.

### Saving model results
Once the 'Save' button becomes available (after resampling and model finalization), this can be used to open up a dialogue box to save modelling results to a location of your choice. The results file is an excel workbook with 4 worksheets: 'testCases' contains the variables used and predicted values for Y in each test fold, 'performance' contains the Train / tune / test results table, 'finalModel' contains the Final version table, and 'importance' contains estimates of predictor importance dervied from ``fitrensemble`` / ``fitcensemble``. These are numerical values between 0 and 1, with higher scores indicating variables that had a greater impact on making predictions.  

# Projections Tab
In this tab the finalized model is used to perform climate change risk assessments according to the scanerios of your choice.

## Climate and crop panel
Use the circular Knobs to select the future decade of interest, the season, the crop distribution (grid cells) to implement the model in, and the crop region. The crop region is used to refine the selected crop distribution to specific climatic regions of Scotland, as defined by the UK Met. Office ([UK Climate Districts Map](https://www.metoffice.gov.uk/research/climate/maps-and-data/about/districts-map)). The crop acronyms are: B = barley, BL = braodleaved tree, C = conifers, O = aots, OSR = oilseed rape, SP = seed potatoes, SF = soft fruit, WP = ware potatoes, and W = wheat. To visualise your selected crop distribution, choose 'crop' from the listbox and a map of Scotland showing the percentage of each grid cell occupied by that crop species will be automatically generated. Similarly, select a climate variable from the listbox to obtain a map of that variable for the decade and season of your choice. 

## Results panel
Click the 'Plot' to produce a boxplot of projected values for your scenario. Each boxplot is a 'super-ensemble' of projected values (12 potential future climates x *n* selected grid cells). Boxes extend from the first to the third quartile, medians are marked in each box, and whiskers extend to 1.5 times the interquartile range. You can display multiple boxplots (i.e. multiple scenarios, such as a different decades / seasons / crops etc.) together in the Projections pane. These will be numbered sequentially. For regression tasks, boxplots show projected values relative to those for the 1981-2000 baseline climatology to show the proportional response; i.e. the percentage change in the response variable relative to baseline conditions. This is just for visualisation purposes and the absolute projected values will be stored for saving. For classification tasks, stacked bar charts are used to show the distribution of projected classes, i.e., the absolute number in each class. These are not taken relative to baseline conditions. Click the 'Clear' button to clear the plot pane. Note that this will also clear the stored projections results.

## Saving projection results
Clicking the 'Save' button will open up a dialogue box to save the projection results that are plotted in the Projections pane to a location of your choice. The results file is an excel workbook with 2 worksheets: 'baseline' contains predictions from your model for UKCP18 modelled baseline conditions (1981-2000), and 'projections' contains the projected values. The column headers are numbered sequentially to match the boxplots in the Projections pane. Note that scenarios comprised of different crop selections will contain a different number of results. 



